{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cats_dogs(CNN).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPLjalVkABDeH7sPaQe3xpi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Meghana1303/Artificial-Neural-Networks/blob/master/cats_dogs(CNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evej5GZXAVwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "train_data_dir = '/content/drive/My Drive/Colab Notebooks/cats-and-dogs/train'\n",
        "validation_data_dir = '/content/drive/My Drive/Colab Notebooks/cats-and-dogs/test'\n",
        "nb_train_samples = 40\n",
        "nb_validation_samples = 10\n",
        "epochs = 10\n",
        "batch_size = 8\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSB-sR-7C9xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "  input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "  input_shape = (img_width, img_height, 3)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxksVxm5DL1S",
        "colab_type": "code",
        "outputId": "ed5e5f6e-1399-4896-da48-f36902211b58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV3uV3QmDQYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRUBTKqDDfaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='binary_crossentropy', # or categorical_crossentropy\n",
        "              optimizer='rmsprop',# or adagrad\n",
        "               metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpsd-vLeDrZI",
        "colab_type": "code",
        "outputId": "a35dddd2-89d8-4f33-e401-d4ec524eed8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "print(train_generator.class_indices)\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "model.save('model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 40 images belonging to 2 classes.\n",
            "{'cat': 0, 'dog': 1}\n",
            "Found 10 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/10\n",
            "5/5 [==============================] - 17s 3s/step - loss: 0.7716 - acc: 0.4500 - val_loss: 0.7460 - val_acc: 0.5000\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 1s 244ms/step - loss: 0.8491 - acc: 0.5750 - val_loss: 0.6783 - val_acc: 0.5000\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 2s 307ms/step - loss: 0.8077 - acc: 0.3750 - val_loss: 0.6869 - val_acc: 0.5000\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 1s 280ms/step - loss: 0.7212 - acc: 0.5000 - val_loss: 0.6921 - val_acc: 0.5000\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 2s 320ms/step - loss: 0.7220 - acc: 0.4250 - val_loss: 0.6945 - val_acc: 0.3750\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 1s 281ms/step - loss: 0.6709 - acc: 0.5750 - val_loss: 2.0395 - val_acc: 0.0000e+00\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 2s 310ms/step - loss: 0.6856 - acc: 0.5750 - val_loss: 0.6880 - val_acc: 0.5000\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 1s 282ms/step - loss: 0.8546 - acc: 0.6500 - val_loss: 0.2232 - val_acc: 1.0000\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 2s 308ms/step - loss: 0.7290 - acc: 0.5500 - val_loss: 0.6876 - val_acc: 0.7500\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 1s 293ms/step - loss: 0.6694 - acc: 0.6750 - val_loss: 0.6307 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ZTOvy4EQmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "\n",
        "# dimensions of our images\n",
        "img_width, img_height = 150, 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_E_RzjlgDxEh",
        "colab_type": "code",
        "outputId": "b2f0a645-2956-4757-e305-54a6aa7c8298",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "# load the model we saved\n",
        "model = load_model('model.h5')\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])   \n",
        "\n",
        "mypath = \"/content/drive/My Drive/Colab Notebooks/cats-and-dogs/test/cat/\"\n",
        "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
        "print(onlyfiles)\n",
        "# predicting images\n",
        "dog_counter = 0 \n",
        "cat_counter  = 0\n",
        "for file in onlyfiles:\n",
        "    img = image.load_img(mypath+file, target_size=(img_width, img_height))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    \n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict_classes(images, batch_size=10)\n",
        "    classes = classes[0][0]\n",
        "    \n",
        "    if classes == 0:\n",
        "        print(file + \": \" + 'cat')\n",
        "        cat_counter += 1\n",
        "    else:\n",
        "        print(file + \": \" + 'dog')\n",
        "        dog_counter += 1\n",
        "print(\"Total Dogs :\",dog_counter)\n",
        "print(\"Total Cats :\",cat_counter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['11.jpg', '34.jpg', '36.jpg', '38.jpg', '45.jpg']\n",
            "11.jpg: cat\n",
            "34.jpg: cat\n",
            "36.jpg: dog\n",
            "38.jpg: dog\n",
            "45.jpg: dog\n",
            "Total Dogs : 3\n",
            "Total Cats : 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ea7L_CpHID5",
        "colab_type": "code",
        "outputId": "634fb5f0-fb30-4dd7-b3cb-1423fc3b29fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#Confution Matrix and Classification Report\n",
        "from sklearn.metrics import classification_report\n",
        "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(validation_generator.classes, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['Cats', 'Dogs']\n",
        "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n",
            "[[5 0]\n",
            " [5 0]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Cats       0.50      1.00      0.67         5\n",
            "        Dogs       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.50        10\n",
            "   macro avg       0.25      0.50      0.33        10\n",
            "weighted avg       0.25      0.50      0.33        10\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}